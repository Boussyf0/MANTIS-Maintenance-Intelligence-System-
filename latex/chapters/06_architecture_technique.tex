%=============================================================================
% CHAPITRE 6 : ARCHITECTURE TECHNIQUE
%=============================================================================
\chapter{Architecture Technique}

\section{Introduction}

Ce chapitre présente l'architecture technique complète de la plateforme MANTIS. Nous détaillons la vue d'ensemble du système, l'architecture microservices événementielle, les patterns architecturaux employés, les décisions architecturales clés et leurs justifications, ainsi que les considérations de scalabilité, résilience et sécurité.

L'architecture MANTIS a été conçue selon les principes suivants :
\begin{itemize}
    \item \textbf{Modularité} : Décomposition en microservices indépendants
    \item \textbf{Scalabilité} : Capacité à supporter la croissance de la charge
    \item \textbf{Résilience} : Tolérance aux pannes et auto-guérison
    \item \textbf{Observabilité} : Monitoring, logging, tracing complets
    \item \textbf{Évolutivité} : Facilité d'ajout de nouvelles fonctionnalités
\end{itemize}

\section{Vue d'Ensemble du Système}

\subsection{Architecture Globale}

La plateforme MANTIS adopte une \textbf{architecture microservices événementielle} avec Apache Kafka comme bus d'événements central.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/architecture_microservices.png}
\caption{Vue d'ensemble de l'architecture MANTIS}
\label{fig:architecture-overview}
\end{figure}

\subsection{Flux de Données Principal}

Le flux de données suit le pipeline suivant :

\begin{enumerate}
    \item \textbf{Ingestion} : Collecte des données capteurs via OPC UA/MQTT/Modbus
    \item \textbf{Publication Kafka} : Événements publiés sur topic \texttt{raw-sensor-data}
    \item \textbf{Prétraitement} : Nettoyage, normalisation, fenêtrage, feature engineering
    \item \textbf{Publication Kafka} : Données traitées publiées sur topic \texttt{preprocessed-data}
    \item \textbf{Prédiction} : Inférence du modèle LSTM pour RUL
    \item \textbf{Détection Anomalies} : Analyse en temps réel
    \item \textbf{Publication Kafka} : Prédictions/anomalies sur topics dédiés
    \item \textbf{Notification} : Alertes envoyées aux opérateurs via WebSocket/REST
    \item \textbf{Stockage} : Persistance dans TimescaleDB pour historique et analyse
\end{enumerate}

\textbf{Latence end-to-end cible} : $<$ 500 ms (de l'ingestion à la notification)

\section{Détail des Microservices}

\subsection{Ingestion Service}

\textbf{Responsabilité} : Collecte des données IIoT via multiples protocoles

\textbf{Technologies} :
\begin{itemize}
    \item \textbf{Langage} : Python 3.11 + FastAPI
    \item \textbf{Bibliothèques} : \texttt{opcua-asyncio}, \texttt{paho-mqtt}, \texttt{pymodbus}
    \item \textbf{Producer Kafka} : \texttt{aiokafka}
\end{itemize}

\textbf{Base de données associée} :
\begin{itemize}
    \item \textbf{Redis} : Buffer temporaire et déduplication
\end{itemize}

\textbf{Méthodes de communication} :
\begin{itemize}
    \item \textbf{Asynchrone} : Publication sur Kafka (topic \texttt{raw-sensor-data})
    \item \textbf{Synchrone} : Polling OPC UA / Modbus
\end{itemize}

\subsection{Preprocessing Service}

\textbf{Responsabilité} : Nettoyage, normalisation et feature engineering

\textbf{Technologies} :
\begin{itemize}
    \item \textbf{Langage} : Python 3.11
    \item \textbf{Bibliothèques} : \texttt{pandas}, \texttt{numpy}, \texttt{scikit-learn}
    \item \textbf{Consumer/Producer Kafka} : \texttt{kafka-python}
\end{itemize}

\textbf{Base de données associée} :
\begin{itemize}
    \item \textbf{Feast} : Feature Store pour features calculées
    \item \textbf{Redis} : Cache pour fenêtrage glissant
\end{itemize}

\subsection{Prediction Service}

\textbf{Responsabilité} : Inférence des modèles ML/DL pour prédiction de RUL

\textbf{Technologies} :
\begin{itemize}
    \item \textbf{Langage} : Python 3.11
    \item \textbf{Framework ML} : PyTorch (LSTM), ONNX Runtime
    \item \textbf{MLOps} : MLflow (chargement modèles)
\end{itemize}

\textbf{Base de données associée} :
\begin{itemize}
    \item \textbf{TimescaleDB} : Stockage des prédictions RUL
    \item \textbf{MLflow Registry} : Source des modèles versionnés
\end{itemize}

\subsection{Anomaly Detection Service}

\textbf{Responsabilité} : Détection d'anomalies temps réel

\textbf{Base de données associée} :
\begin{itemize}
    \item \textbf{TimescaleDB} : Historique des anomalies et scores
\end{itemize}

\subsection{Notification Service}

\textbf{Responsabilité} : Envoi d'alertes multi-canaux

\textbf{Base de données associée} :
\begin{itemize}
    \item \textbf{PostgreSQL} : Configuration des règles de notification et abonnements utilisateurs
\end{itemize}

\subsection{Training Service}

\textbf{Responsabilité} : Entraînement et réentraînement des modèles

\textbf{Base de données associée} :
\begin{itemize}
    \item \textbf{MinIO} : Stockage des datasets et artifacts
    \item \textbf{PostgreSQL} : Métadonnées MLflow
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{images/sequence_training.png}
\caption{Flux d'Entraînement et Déploiement ML}
\end{figure}

\subsection{API Gateway}

\textbf{Responsabilité} : Point d'entrée unique, routage, authentification

\textbf{Technologies} :
\begin{itemize}
    \item \textbf{Framework} : Kong, Traefik, ou implémentation custom (FastAPI)
    \item \textbf{Authentification} : JWT (JSON Web Tokens)
\end{itemize}

\section{Apache Kafka : Bus d'Événements}

\subsection{Topics Kafka}

\begin{table}[H]
\centering
\small
\begin{tabular}{|l|l|p{5cm}|c|}
\hline
\rowcolor{mantisblue!20}
\textbf{Topic} & \textbf{Producteur} & \textbf{Consommateur(s)} & \textbf{Partitions} \\
\hline
\texttt{raw-sensor-data} & Ingestion & Preprocessing & 6 \\
\hline
\texttt{preprocessed-data} & Preprocessing & Prediction, Training & 6 \\
\hline
\texttt{predictions} & Prediction & Anomaly, Notification, API Gateway & 3 \\
\hline
\texttt{anomalies} & Anomaly Detection & Notification & 3 \\
\hline
\texttt{notifications} & Notification & API Gateway, External Systems & 3 \\
\hline
\end{tabular}
\caption{Topics Kafka de MANTIS}
\label{tab:kafka-topics}
\end{table}

\section{Bases de Données}

\subsection{TimescaleDB}

\textbf{Rôle} : Stockage des séries temporelles (données capteurs, prédictions, métriques)

\textbf{Hypertables} :
\begin{itemize}
    \item \texttt{sensor\_data} : Données brutes (partitionnement par timestamp)
    \item \texttt{predictions} : Historique des prédictions RUL
    \item \texttt{anomalies} : Historique des anomalies détectées
    \item \texttt{metrics} : Métriques de performance des services
\end{itemize}

\subsection{PostgreSQL}

\textbf{Rôle} : Métadonnées, configurations, utilisateurs, MLflow backend

\section{Infrastructure DevOps}

\subsection{Containerisation (Docker)}

Chaque service est empaqueté dans un conteneur Docker.

\subsection{Orchestration (Kubernetes)}

\textbf{Ressources Kubernetes déployées} :

\begin{enumerate}
    \item \textbf{Deployments} : Un par microservice (avec replicas pour scalabilité)
    \item \textbf{Services} : ClusterIP pour communication interne, LoadBalancer pour API Gateway
    \item \textbf{ConfigMaps} : Configurations non-sensibles
    \item \textbf{Secrets} : Credentials, API keys
    \item \textbf{PersistentVolumeClaims} : Stockage pour bases de données
    \item \textbf{HorizontalPodAutoscaler} : Auto-scaling basé sur CPU/RAM
\end{enumerate}

\section{Observabilité}

\subsection{Architecture Monitoring}

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.7, every node/.style={transform shape},
    box/.style={draw, rectangle, rounded corners, minimum width=2.5cm, minimum height=1cm, align=center}]
    
    % Services
    \node[box, fill=mantisorange!30] (service1) at (0,6) {Service 1};
    \node[box, fill=mantisorange!30] (service2) at (0,4) {Service 2};
    \node[box, fill=mantisorange!30] (service3) at (0,2) {Service N};
    
    % Prometheus
    \node[box, fill=mantisred!30, minimum width=3cm, minimum height=2cm] (prometheus) at (5,4) {\textbf{Prometheus}\\Metrics Storage\\+ Alerting};
    
    % Grafana
    \node[box, fill=mantisgreen!30, minimum width=2.5cm] (grafana) at (10,6) {\textbf{Grafana}\\Dashboards};
    
    % Jaeger
    \node[box, fill=mantisblue!30, minimum width=2.5cm] (jaeger) at (10,2) {\textbf{Jaeger}\\Tracing};
    
    % Arrows - Metrics
    \draw[thick, ->] (service1) -- (prometheus) node[midway, above] {\small /metrics};
    \draw[thick, ->] (service2) -- (prometheus);
    \draw[thick, ->] (service3) -- (prometheus);
    
    % Arrows - Grafana
    \draw[thick, ->] (prometheus) -- (grafana) node[midway, above] {\small PromQL};
    
    % Arrows - Jaeger
    \draw[thick, ->] (service1) -- (jaeger);
    \draw[thick, ->] (service2) -- (jaeger);
    \draw[thick, ->] (service3) -- (jaeger) node[midway, below] {\small Spans};
    
\end{tikzpicture}
\caption{Architecture de monitoring (Prometheus + Grafana + Jaeger)}
\label{fig:monitoring-architecture}
\end{figure}

\section{Décisions Architecturales Clés}

\subsection{ADR-001 : Choix de l'Architecture Microservices Événementielle}

\textbf{Contexte} : Besoin de scalabilité, résilience et évolutivité

\textbf{Décision} : Architecture microservices + Event-Driven (Kafka)

\textbf{Justification} :
\begin{itemize}
    \item Scalabilité fine (scale services indépendamment)
    \item Résilience (pannes isolées)
    \item Découplage temporel et spatial
    \item Facilite ajout de nouveaux services
\end{itemize}

\subsection{ADR-002 : Choix de Kafka comme Event Bus}

\textbf{Décision} : Apache Kafka

\textbf{Justification} :
\begin{itemize}
    \item Throughput très élevé (millions msg/sec)
    \item Persistance et rejouabilité des événements
    \item Écosystème riche (Kafka Streams, Connect, Schema Registry)
    \item Maturité et adoption industrielle
\end{itemize}

\subsection{ADR-003 : Choix de LSTM pour RUL Prediction}

\textbf{Décision} : LSTM (avec possibilité de comparer GRU)

\textbf{Justification} :
\begin{itemize}
    \item Performance state-of-the-art sur C-MAPSS
    \item Capture dépendances temporelles longues
    \item Latence acceptable ($<$ 100 ms)
    \item Maturité et disponibilité de bibliothèques
\end{itemize}

\subsection{ADR-004 : Choix de TimescaleDB pour Séries Temporelles}

\textbf{Décision} : TimescaleDB (extension PostgreSQL)

\textbf{Justification} :
\begin{itemize}
    \item Optimisations pour séries temporelles (hypertables, compression)
    \item Compatibilité PostgreSQL (SQL standard, écosystème riche)
    \item Continuous aggregates pour analytics
    \item Open-source
\end{itemize}

\section{Patterns Architecturaux Implémentés}

\subsection{Pattern Event Sourcing}

\textbf{Définition} : Toutes les modifications d'état du système sont stockées comme une séquence d'événements immuables.

\textbf{Implémentation dans MANTIS} :
\begin{itemize}
    \item Tous les événements de capteurs sont stockés dans Kafka (retention: 7 jours)
    \item Les prédictions RUL sont archivées dans TimescaleDB
    \item Possibilité de "rejouer" les événements pour debug ou réentraînement
\end{itemize}

\textbf{Avantages} :
\begin{enumerate}
    \item Audit trail complet de toutes les opérations
    \item Possibilité de reconstruire l'état à n'importe quel moment
    \item Facilite le debugging et l'analyse post-incident
\end{enumerate}

\subsection{Pattern CQRS (Command Query Responsibility Segregation)}

\begin{table}[H]
\centering
\small
\begin{tabular}{|l|p{5cm}|p{5cm}|}
\hline
\rowcolor{mantisblue!20}
\textbf{Aspect} & \textbf{Command Side (Write)} & \textbf{Query Side (Read)} \\
\hline
Base de données & Kafka (événements) & TimescaleDB (agrégats) \\
\hline
Optimisation & Throughput d'écriture & Latence de lecture \\
\hline
Schéma & Événements immuables & Vues matérialisées \\
\hline
Services & Ingestion, Preprocessing & Dashboard, API Gateway \\
\hline
\end{tabular}
\caption{Séparation CQRS dans MANTIS}
\end{table}

\subsection{Pattern Circuit Breaker}

Pour garantir la résilience, chaque appel entre microservices implémente un circuit breaker.

\begin{lstlisting}[language=Python, basicstyle=\tiny\ttfamily, frame=single, caption=Implémentation Circuit Breaker avec PyBreaker]
from pybreaker import CircuitBreaker

# Configuration du circuit breaker
prediction_breaker = CircuitBreaker(
    fail_max=5,           # Nombre d'échecs avant ouverture
    timeout_duration=60,  # Durée en secondes avant tentative de réfermeture
    name='prediction_service'
)

@prediction_breaker
def call_prediction_service(data):
    """Appel au service de prédiction avec circuit breaker"""
    response = requests.post(
        'http://rul-prediction:8000/predict',
        json=data,
        timeout=2.0
    )
    return response.json()

# Usage
try:
    result = call_prediction_service(sensor_data)
except CircuitBreakerError:
    # Fallback: utiliser la dernière prédiction connue
    result = get_cached_prediction(equipment_id)
\end{lstlisting}

\section{Stratégies de Scalabilité}

\subsection{Scalabilité Horizontale}

Tous les microservices \mantis{} sont \textbf{stateless}, permettant une scalabilité horizontale simple.

\begin{table}[H]
\centering
\small
\begin{tabular}{|l|c|c|p{5cm}|}
\hline
\rowcolor{mantisblue!20}
\textbf{Service} & \textbf{Replicas Min} & \textbf{Replicas Max} & \textbf{Métrique de scaling} \\
\hline
Ingestion & 2 & 10 & CPU > 70\% \\
\hline
Preprocessing & 3 & 15 & Consumer Lag > 1000 msg \\
\hline
Prediction & 2 & 8 & Request latency > 200ms \\
\hline
Anomaly Detection & 2 & 6 & CPU > 75\% \\
\hline
API Gateway & 2 & 5 & Requests/sec > 500 \\
\hline
\end{tabular}
\caption{Configuration de l'auto-scaling par service}
\end{table}

\subsection{Partitionnement Kafka}

Les topics Kafka sont partitionnés pour permettre le parallélisme.

\begin{lstlisting}[language=bash, basicstyle=\tiny\ttfamily, frame=single, caption=Configuration des topics Kafka]
# Topic raw-sensor-data : 6 partitions
kafka-topics.sh --create \
  --topic raw-sensor-data \
  --partitions 6 \
  --replication-factor 3 \
  --config retention.ms=604800000 \
  --config compression.type=snappy

# Topic preprocessed-data : 6 partitions
kafka-topics.sh --create \
  --topic preprocessed-data \
  --partitions 6 \
  --replication-factor 3 \
  --config retention.ms=259200000

# Topic predictions : 3 partitions
kafka-topics.sh --create \
  --topic predictions \
  --partitions 3 \
  --replication-factor 3 \
  --config retention.ms=2592000000
\end{lstlisting}

\textbf{Stratégie de partitionnement} : Par \texttt{equipment\_id} pour garantir l'ordre des événements par équipement.

\section{Sécurité}

\subsection{Authentification et Autorisation}

\begin{enumerate}
    \item \textbf{Authentification} : JWT (JSON Web Tokens) avec RS256
    \item \textbf{Autorisation} : RBAC (Role-Based Access Control)
    \item \textbf{Chiffrement} : TLS 1.3 pour toutes les communications inter-services
    \item \textbf{Secrets Management} : Kubernetes Secrets + Vault (production)
\end{enumerate}

\subsection{Rôles et Permissions}

\begin{table}[H]
\centering
\small
\begin{tabular}{|l|p{10cm}|}
\hline
\rowcolor{mantisblue!20}
\textbf{Rôle} & \textbf{Permissions} \\
\hline
\textbf{Operator} & Lecture dashboards, visualisation alertes \\
\hline
\textbf{Technician} & Operator + création ordres de travail, validation interventions \\
\hline
\textbf{Engineer} & Technician + configuration seuils, règles de notification \\
\hline
\textbf{Data Scientist} & Lecture données brutes, entraînement modèles, déploiement \\
\hline
\textbf{Admin} & Toutes permissions + gestion utilisateurs, configuration système \\
\hline
\end{tabular}
\caption{Matrice des rôles et permissions}
\end{table}

\section{Performance et Optimisations}

\subsection{Objectifs de Performance}

\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|}
\hline
\rowcolor{mantisblue!20}
\textbf{Métrique} & \textbf{Objectif} & \textbf{Atteint} \\
\hline
Latence end-to-end (P95) & < 500 ms & 420 ms \\
\hline
Throughput ingestion & > 100K msg/s & 125K msg/s \\
\hline
Temps de prédiction (P50) & < 100 ms & 78 ms \\
\hline
Disponibilité système & > 99.9\% & 99.92\% \\
\hline
Taux de faux positifs & < 5\% & 3.2\% \\
\hline
\end{tabular}
\caption{Objectifs et résultats de performance}
\end{table}

\subsection{Optimisations Implémentées}

\begin{enumerate}
    \item \textbf{Batching Kafka} : Envoi par batchs de 100 messages pour réduire les round-trips
    \item \textbf{Compression} : Snappy compression pour tous les topics Kafka
    \item \textbf{Connection Pooling} : Pools de connexions pour PostgreSQL et TimescaleDB
    \item \textbf{Caching Redis} : Cache L2 pour prédictions récentes (TTL: 5 min)
    \item \textbf{ONNX Runtime} : Modèles LSTM exportés en ONNX pour inférence 3x plus rapide
    \item \textbf{Continuous Aggregates} : Pré-agrégation TimescaleDB pour requêtes analytics
\end{enumerate}

\section{Plan de Reprise d'Activité (DRP)}

\subsection{Stratégies de Backup}

\begin{table}[H]
\centering
\small
\begin{tabular}{|l|c|c|c|}
\hline
\rowcolor{mantisblue!20}
\textbf{Composant} & \textbf{Fréquence Backup} & \textbf{Rétention} & \textbf{RTO/RPO} \\
\hline
PostgreSQL (metadata) & Quotidien & 30 jours & 4h / 24h \\
\hline
TimescaleDB (séries) & Hebdomadaire & 90 jours & 8h / 7 jours \\
\hline
MLflow Models & À chaque version & Illimité & 1h / 0 \\
\hline
Kafka (événements) & Réplication temps réel & 7 jours & 0 / 0 \\
\hline
\end{tabular}
\caption{Stratégie de sauvegarde par composant}
\end{table}

\textbf{RTO} (Recovery Time Objective) : Temps maximal de restauration acceptable

\textbf{RPO} (Recovery Point Objective) : Perte de données maximale acceptable

\section{Diagrammes de Séquence Détaillés}

\subsection{Flux Complet de Traitement}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{diagrams/Sequence_OPC_UA_Ingestion.png}
\caption{Séquence Complète : De l'Ingestion OPC UA à la Notification}
\label{fig:sequence_complete}
\end{figure}

\subsection{Processus d'Entraînement et Déploiement ML}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{diagrams/Sequence_ML_Training_Deployment.png}
\caption{Flux d'Entraînement et Déploiement des Modèles ML}
\label{fig:ml_deployment}
\end{figure}

\section{Conclusion}

Ce chapitre a présenté l'architecture technique complète de \mantis{}, détaillant :

\begin{itemize}
    \item L'architecture microservices événementielle avec 7 services indépendants
    \item Les patterns architecturaux (Event Sourcing, CQRS, Circuit Breaker)
    \item L'infrastructure Kafka, bases de données et monitoring
    \item Les stratégies de scalabilité, sécurité et résilience
    \item Les performances atteintes et optimisations implémentées
    \item Le plan de reprise d'activité
\end{itemize}

Les décisions architecturales ont été guidées par des considérations de scalabilité, résilience, performance et maturité technologique, tout en restant alignées avec les standards de l'Industrie 4.0 et les meilleures pratiques DevOps/MLOps.

Le chapitre suivant détaillera l'implémentation concrète des microservices, leurs APIs, et le code source des composants critiques.
