{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "colab-setup"
            },
            "outputs": [],
            "source": [
                "# @title Setup for Google Colab\n",
                "# Run this cell if you are using Google Colab to set up the environment.\n",
                "\n",
                "try:\n",
                "    import google.colab\n",
                "    IN_COLAB = True\n",
                "except:\n",
                "    IN_COLAB = False\n",
                "\n",
                "if IN_COLAB:\n",
                "    print(\"Running in Google Colab. Setting up environment...\")\n",
                "    \n",
                "    # 1. Clone the repository\n",
                "    !git clone https://github.com/Boussyf0/MANTIS-Maintenance-Intelligence-System-.git mantis_repo\n",
                "    \n",
                "    # 2. Change working directory\n",
                "    import os\n",
                "    os.chdir('mantis_repo')\n",
                "    \n",
                "    # 3. Create data directories\n",
                "    if not os.path.exists('data/raw/NASA_CMAPSS'):\n",
                "        os.makedirs('data/raw/NASA_CMAPSS')\n",
                "    \n",
                "    # 4. Download and unzip dataset (Robust w/ mirrors)\n",
                "    if not os.path.exists('data/raw/NASA_CMAPSS/train_FD001.txt'):\n",
                "        print(\"Downloading NASA CMAPSS Data...\")\n",
                "        \n",
                "        urls = [\n",
                "            'https://data.nasa.gov/api/views/s96h-rxk2/files/8b8e05a8-6f16-43b6-96b6-81a171ef9948?download=true&filename=CMAPSSData.zip',\n",
                "            'https://raw.githubusercontent.com/senthilnayagan/CMS_DeepLearning/master/CMAPSSData.zip',\n",
                "            'https://data.nasa.gov/docs/legacy/CMAPSSData.zip'\n",
                "        ]\n",
                "        \n",
                "        success = False\n",
                "        for url in urls:\n",
                "            print(f\"Trying {url}...\")\n",
                "            try:\n",
                "                exit_code = os.system(f'wget \"{url}\" -O data/raw/NASA_CMAPSS/CMAPSSData.zip')\n",
                "                if exit_code == 0:\n",
                "                    success = True\n",
                "                    print(\"Download successful.\")\n",
                "                    break\n",
                "            except Exception as e:\n",
                "                print(f\"Failed: {e}\")\n",
                "        \n",
                "        if success:\n",
                "            !unzip -o data/raw/NASA_CMAPSS/CMAPSSData.zip -d data/raw/NASA_CMAPSS/\n",
                "            print(\"Data extracted.\")\n",
                "    \n",
                "    # 5. Install MLflow\n",
                "    !pip install mlflow\n",
                "\n",
                "    # 6. Switch to notebooks directory so relative paths work\n",
                "    os.chdir('notebooks')\n",
                "    print(\"Setup complete. Current working directory:\", os.getcwd())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Optimisation des Hyperparamètres LSTM (MLflow)\n",
                "\n",
                "Ce notebook implémente une recherche sur grille (Grid Search) pour optimiser les hyperparamètres du modèle LSTM de prédiction RUL. \n",
                "\n",
                "**Configuration Colab** :\n",
                "- Epochs: 100\n",
                "- Tracking MLflow: Local (`file:./mlruns`)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import mlflow\n",
                "import mlflow.pytorch\n",
                "from pathlib import Path\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "import math\n",
                "import itertools\n",
                "\n",
                "# Configure MLflow (Local pour Colab)\n",
                "MLFLOW_TRACKING_URI = \"file:./mlruns\"\n",
                "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
                "\n",
                "# Experiment Name\n",
                "experiment_name = \"MANTIS_RUL_Prediction_Colab\"\n",
                "mlflow.set_experiment(experiment_name)\n",
                "\n",
                "def log(msg):\n",
                "    print(msg)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- MODEL DEFINITION ---\n",
                "class RULModel(nn.Module):\n",
                "    def __init__(self, input_size, hidden_size, num_layers, output_size=1):\n",
                "        super(RULModel, self).__init__()\n",
                "        self.hidden_size = hidden_size\n",
                "        self.num_layers = num_layers\n",
                "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
                "        self.fc = nn.Linear(hidden_size, output_size)\n",
                "\n",
                "    def forward(self, x):\n",
                "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
                "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
                "        out, _ = self.lstm(x, (h0, c0))\n",
                "        out = self.fc(out[:, -1, :])\n",
                "        return out"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- PREPARATION DATA ---\n",
                "def prepare_data(data_path, sequence_length=30):\n",
                "    cols = ['unit_number', 'time_cycles'] + ['setting_1', 'setting_2', 'setting_3'] + [f'sensor_{i}' for i in range(1, 22)]\n",
                "    df = pd.read_csv(data_path, sep=r'\\s+', header=None, names=cols)\n",
                "    \n",
                "    max_cycles = df.groupby('unit_number')['time_cycles'].transform('max')\n",
                "    df['RUL'] = max_cycles - df['time_cycles']\n",
                "    \n",
                "    USEFUL_SENSORS = ['sensor_2', 'sensor_3', 'sensor_4', 'sensor_7', 'sensor_8', \n",
                "                      'sensor_9', 'sensor_11', 'sensor_12', 'sensor_13', 'sensor_14', \n",
                "                      'sensor_15', 'sensor_17', 'sensor_20', 'sensor_21']\n",
                "    \n",
                "    scaler = MinMaxScaler()\n",
                "    df[USEFUL_SENSORS] = scaler.fit_transform(df[USEFUL_SENSORS])\n",
                "    \n",
                "    sequences = []\n",
                "    labels = []\n",
                "    \n",
                "    for unit in df['unit_number'].unique():\n",
                "        unit_data = df[df['unit_number'] == unit]\n",
                "        if len(unit_data) < sequence_length:\n",
                "            continue\n",
                "            \n",
                "        data_array = unit_data[USEFUL_SENSORS].values\n",
                "        rul_array = unit_data['RUL'].values\n",
                "        \n",
                "        for i in range(len(unit_data) - sequence_length):\n",
                "            sequences.append(data_array[i:i+sequence_length])\n",
                "            labels.append(rul_array[i+sequence_length])\n",
                "            \n",
                "    return np.array(sequences), np.array(labels), len(USEFUL_SENSORS)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- TRAIN FUNCTION ---\n",
                "def train_and_evaluate(params, X_train, y_train, X_val, y_val, input_size):\n",
                "    hidden_size = params['hidden_size']\n",
                "    num_layers = params['num_layers']\n",
                "    lr = params['lr']\n",
                "    epochs = 100  # Set to 100 as requested\n",
                "    batch_size = 64\n",
                "    \n",
                "    run_name = f\"LSTM_H{hidden_size}_L{num_layers}_LR{lr}\"\n",
                "    \n",
                "    with mlflow.start_run(run_name=run_name):\n",
                "        log(f\"--- Starting Run: {run_name} (Epochs={epochs}) ---\")\n",
                "        # Log params\n",
                "        mlflow.log_param(\"hidden_size\", hidden_size)\n",
                "        mlflow.log_param(\"num_layers\", num_layers)\n",
                "        mlflow.log_param(\"learning_rate\", lr)\n",
                "        mlflow.log_param(\"epochs\", epochs)\n",
                "        mlflow.log_param(\"batch_size\", batch_size)\n",
                "        \n",
                "        model = RULModel(input_size, hidden_size, num_layers)\n",
                "        criterion = nn.MSELoss()\n",
                "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
                "        \n",
                "        best_rmse = float('inf')\n",
                "        \n",
                "        for epoch in range(epochs):\n",
                "            model.train()\n",
                "            permutation = torch.randperm(X_train.size()[0])\n",
                "            for i in range(0, X_train.size()[0], batch_size):\n",
                "                indices = permutation[i:i+batch_size]\n",
                "                batch_x, batch_y = X_train[indices], y_train[indices]\n",
                "                \n",
                "                optimizer.zero_grad()\n",
                "                outputs = model(batch_x)\n",
                "                loss = criterion(outputs, batch_y)\n",
                "                loss.backward()\n",
                "                optimizer.step()\n",
                "            \n",
                "            # Validation\n",
                "            model.eval()\n",
                "            with torch.no_grad():\n",
                "                val_preds = model(X_val)\n",
                "                val_loss = criterion(val_preds, y_val)\n",
                "                rmse = math.sqrt(val_loss.item())\n",
                "                if rmse < best_rmse:\n",
                "                    best_rmse = rmse\n",
                "                \n",
                "                mlflow.log_metric(\"rmse\", rmse, step=epoch)\n",
                "            \n",
                "            if epoch % 10 == 0:\n",
                "                print(f\"Epoch {epoch}/{epochs} - RMSE: {rmse:.4f}\")\n",
                "                \n",
                "        log(f\"Run Finished. Best RMSE: {best_rmse:.4f}\")\n",
                "        mlflow.log_metric(\"best_rmse\", best_rmse)\n",
                "        mlflow.pytorch.log_model(model, \"lstm_model\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- EXECUTION ---\n",
                "try:\n",
                "    DATA_PATH = Path('../../data/raw/NASA_CMAPSS/train_FD001.txt')\n",
                "    \n",
                "    log(\"Loading and preprocessing data...\")\n",
                "    X, y, input_size = prepare_data(DATA_PATH)\n",
                "    \n",
                "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
                "    y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
                "    \n",
                "    train_size = int(len(X) * 0.8)\n",
                "    X_train, X_val = X_tensor[:train_size], X_tensor[train_size:]\n",
                "    y_train, y_val = y_tensor[:train_size], y_tensor[train_size:]\n",
                "    \n",
                "    # HYPERPARAMETER GRID\n",
                "    param_grid = {\n",
                "        'hidden_size': [50, 100],\n",
                "        'num_layers': [1, 2],\n",
                "        'lr': [0.001]\n",
                "    }\n",
                "    \n",
                "    keys, values = zip(*param_grid.items())\n",
                "    combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
                "    \n",
                "    log(f\"Starting Grid Search with {len(combinations)} combinations...\")\n",
                "    \n",
                "    for i, params in enumerate(combinations):\n",
                "        log(f\"\\nProcessing combination {i+1}/{len(combinations)}: {params}\")\n",
                "        train_and_evaluate(params, X_train, y_train, X_val, y_val, input_size)\n",
                "    \n",
                "    log(\"\\nGrid Search Complete. Check MLflow runs.\")\n",
                "\n",
                "except Exception as e:\n",
                "    import traceback\n",
                "    log(f\"ERROR: {e}\")\n",
                "    log(traceback.format_exc())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}