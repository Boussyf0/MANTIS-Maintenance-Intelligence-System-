{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "colab-setup",
        "outputId": "c2c308fb-ef39-49cb-ecce-57c01e10d396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab. Setting up environment...\n",
            "Cloning into 'mantis_repo'...\n",
            "remote: Enumerating objects: 749, done.\u001b[K\n",
            "remote: Counting objects: 100% (95/95), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 749 (delta 4), reused 70 (delta 4), pack-reused 654 (from 1)\u001b[K\n",
            "Receiving objects: 100% (749/749), 102.09 MiB | 18.37 MiB/s, done.\n",
            "Resolving deltas: 100% (182/182), done.\n",
            "Downloading NASA CMAPSS Data...\n",
            "Trying https://data.nasa.gov/api/views/s96h-rxk2/files/8b8e05a8-6f16-43b6-96b6-81a171ef9948?download=true&filename=CMAPSSData.zip...\n",
            "Trying https://raw.githubusercontent.com/senthilnayagan/CMS_DeepLearning/master/CMAPSSData.zip...\n",
            "Trying https://data.nasa.gov/docs/legacy/CMAPSSData.zip...\n",
            "Download successful.\n",
            "Archive:  data/raw/NASA_CMAPSS/CMAPSSData.zip\n",
            "  inflating: data/raw/NASA_CMAPSS/Damage Propagation Modeling.pdf  \n",
            "  inflating: data/raw/NASA_CMAPSS/readme.txt  \n",
            "  inflating: data/raw/NASA_CMAPSS/RUL_FD001.txt  \n",
            "  inflating: data/raw/NASA_CMAPSS/RUL_FD002.txt  \n",
            "  inflating: data/raw/NASA_CMAPSS/RUL_FD003.txt  \n",
            "  inflating: data/raw/NASA_CMAPSS/RUL_FD004.txt  \n",
            "  inflating: data/raw/NASA_CMAPSS/test_FD001.txt  \n",
            "  inflating: data/raw/NASA_CMAPSS/test_FD002.txt  \n",
            "  inflating: data/raw/NASA_CMAPSS/test_FD003.txt  \n",
            "  inflating: data/raw/NASA_CMAPSS/test_FD004.txt  \n",
            "  inflating: data/raw/NASA_CMAPSS/train_FD001.txt  \n",
            "  inflating: data/raw/NASA_CMAPSS/train_FD002.txt  \n",
            "  inflating: data/raw/NASA_CMAPSS/train_FD003.txt  \n",
            "  inflating: data/raw/NASA_CMAPSS/train_FD004.txt  \n",
            "Data extracted.\n",
            "Setup complete. Current working directory: /content/mantis_repo/notebooks\n"
          ]
        }
      ],
      "source": [
        "# @title Setup for Google Colab\n",
        "# Run this cell if you are using Google Colab to set up the environment.\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"Running in Google Colab. Setting up environment...\")\n",
        "\n",
        "    # 1. Clone the repository\n",
        "    !git clone https://github.com/Boussyf0/MANTIS-Maintenance-Intelligence-System-.git mantis_repo\n",
        "\n",
        "    # 2. Change working directory\n",
        "    import os\n",
        "    os.chdir('mantis_repo')\n",
        "\n",
        "    # 3. Create data directories\n",
        "    if not os.path.exists('data/raw/NASA_CMAPSS'):\n",
        "        os.makedirs('data/raw/NASA_CMAPSS')\n",
        "\n",
        "    # 4. Download and unzip dataset (Robust w/ mirrors)\n",
        "    if not os.path.exists('data/raw/NASA_CMAPSS/train_FD001.txt'):\n",
        "        print(\"Downloading NASA CMAPSS Data...\")\n",
        "\n",
        "        urls = [\n",
        "            'https://data.nasa.gov/api/views/s96h-rxk2/files/8b8e05a8-6f16-43b6-96b6-81a171ef9948?download=true&filename=CMAPSSData.zip',\n",
        "            'https://raw.githubusercontent.com/senthilnayagan/CMS_DeepLearning/master/CMAPSSData.zip',\n",
        "            'https://data.nasa.gov/docs/legacy/CMAPSSData.zip'\n",
        "        ]\n",
        "\n",
        "        success = False\n",
        "        for url in urls:\n",
        "            print(f\"Trying {url}...\")\n",
        "            try:\n",
        "                exit_code = os.system(f'wget \"{url}\" -O data/raw/NASA_CMAPSS/CMAPSSData.zip')\n",
        "                if exit_code == 0:\n",
        "                    success = True\n",
        "                    print(\"Download successful.\")\n",
        "                    break\n",
        "            except Exception as e:\n",
        "                print(f\"Failed: {e}\")\n",
        "\n",
        "        if success:\n",
        "            !unzip -o data/raw/NASA_CMAPSS/CMAPSSData.zip -d data/raw/NASA_CMAPSS/\n",
        "            print(\"Data extracted.\")\n",
        "        else:\n",
        "            print(\"CRITICAL: All download mirrors failed. Please upload data manually.\")\n",
        "\n",
        "    # 5. Switch to notebooks directory so relative paths work\n",
        "    os.chdir('notebooks')\n",
        "    print(\"Setup complete. Current working directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysLsCjCTrCKp"
      },
      "source": [
        "# Feature Engineering & Extraction (FD001)\n",
        "\n",
        "Ce notebook charge les données brutes C-MAPSS FD001, effectue le nettoyage, la normalisation, et l'extraction de features (moyennes/écarts-types glissants).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldNoSA02rCKq",
        "outputId": "6c1e8d04-2061-4b84-c56e-0c1e61334145"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement des données...\n",
            "Train: (20631, 26), Test: (13096, 26)\n",
            "Calcul des features...\n",
            "Données traitées sauvegardées dans ../data/processed\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Config\n",
        "DATA_PATH = Path('../../data/raw/NASA_CMAPSS')\n",
        "PROCESSED_PATH = Path('../../data/processed')\n",
        "PROCESSED_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Colonnes\n",
        "index_cols = ['unit_number', 'time_cycles']\n",
        "setting_cols = ['setting_1', 'setting_2', 'setting_3']\n",
        "sensor_cols = [f'sensor_{i}' for i in range(1, 22)]\n",
        "cols = index_cols + setting_cols + sensor_cols\n",
        "\n",
        "# Chargement\n",
        "print(\"Chargement des données...\")\n",
        "train = pd.read_csv(DATA_PATH / 'train_FD001.txt', sep='\\\\s+', header=None, names=cols)\n",
        "test = pd.read_csv(DATA_PATH / 'test_FD001.txt', sep='\\\\s+', header=None, names=cols)\n",
        "y_test = pd.read_csv(DATA_PATH / 'RUL_FD001.txt', sep='\\\\s+', header=None, names=['RUL'])\n",
        "\n",
        "print(f\"Train: {train.shape}, Test: {test.shape}\")\n",
        "\n",
        "# --- 1. Calcul de la RUL (Target) sur le Train ---\n",
        "def add_rul(df):\n",
        "    max_cycles = df.groupby('unit_number')['time_cycles'].transform('max')\n",
        "    df['RUL'] = max_cycles - df['time_cycles']\n",
        "    return df\n",
        "\n",
        "train = add_rul(train)\n",
        "\n",
        "# --- 2. Normalisation ---\n",
        "scaler = MinMaxScaler()\n",
        "train[sensor_cols] = scaler.fit_transform(train[sensor_cols])\n",
        "test[sensor_cols] = scaler.transform(test[sensor_cols])\n",
        "\n",
        "# --- 3. Feature Engineering (Rolling Windows) ---\n",
        "def compute_rolling_features(df, window=20):\n",
        "    sensor_cols = [c for c in df.columns if 'sensor' in c]\n",
        "    rolled = df.groupby('unit_number')[sensor_cols].rolling(window=window, min_periods=1)\n",
        "\n",
        "    feat_mean = rolled.mean().reset_index(level=0, drop=True).add_suffix(f'_mean{window}')\n",
        "    feat_std = rolled.std().reset_index(level=0, drop=True).add_suffix(f'_std{window}')\n",
        "\n",
        "    return pd.concat([df, feat_mean, feat_std], axis=1).fillna(0)\n",
        "\n",
        "print(\"Calcul des features...\")\n",
        "train_feat = compute_rolling_features(train)\n",
        "test_feat = compute_rolling_features(test)\n",
        "\n",
        "# --- 4. Sauvegarde ---\n",
        "train_feat.to_csv(PROCESSED_PATH / 'train_FD001_features.csv', index=False)\n",
        "test_feat.to_csv(PROCESSED_PATH / 'test_FD001_features.csv', index=False)\n",
        "\n",
        "print(\"Données traitées sauvegardées dans\", PROCESSED_PATH)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}