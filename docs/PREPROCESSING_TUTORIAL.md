# Preprocessing Service Tutorial
## Building MANTIS Service #2

---

## ğŸ¯ Learning Objectives

By the end of this tutorial, you will understand:
1. Why preprocessing is critical for ML pipelines
2. Common data quality issues and how to fix them
3. How to build a production-ready FastAPI service
4. How to consume from and produce to Kafka
5. How to test and deploy the service

---

## ğŸ“Š The Data Quality Problem

### Real Sensor Data Issues

#### **Problem 1: Sensor Glitches (Outliers)**
```
Time    Temperature    Issue
10:00   75.2Â°C        âœ… Normal
10:01   75.5Â°C        âœ… Normal
10:02   999.9Â°C       âŒ Sensor returned error code as temperature!
10:03   75.3Â°C        âœ… Normal
```
**Impact:** ML model thinks temperature spiked to 999Â°C â†’ false alarm!

**Solution:** Detect and remove outliers using statistical methods (IQR, Z-score)

---

#### **Problem 2: Missing Data**
```
Time    Vibration    Cause
10:00   45 Hz       âœ… Good
10:01   46 Hz       âœ… Good
10:02   NULL        âŒ Sensor disconnected
10:03   NULL        âŒ Still disconnected
10:04   47 Hz       âœ… Reconnected
```
**Impact:** ML models can't handle NULL values â†’ crash or skip data

**Solutions:**
- **Forward fill:** Use last known value (45â†’45â†’45â†’45â†’47)
- **Interpolation:** Estimate middle values (45â†’46â†’46.33â†’46.66â†’47)
- **Drop:** If too many missing values, discard the window

---

#### **Problem 3: Different Scales**
```
Sensor          Min    Max     Unit
Temperature     20     100     Â°C
Vibration       0      1000    Hz
Pressure        0      10      bar
Current         0      500     A
```
**Problem:** Vibration (0-1000) dominates calculations over Pressure (0-10)

**Solution:** Normalize all sensors to 0-1 range
```python
normalized = (value - min) / (max - min)
# Temperature 75Â°C â†’ (75-20)/(100-20) = 0.6875
# Vibration 500Hz â†’ (500-0)/(1000-0) = 0.5
```

---

#### **Problem 4: High-Frequency Noise**
```
Time    Vibration (Raw)    Vibration (Smoothed)
10:00   45.2 Hz           45.0 Hz
10:01   46.8 Hz           45.5 Hz
10:02   44.1 Hz           45.3 Hz
10:03   47.3 Hz           45.8 Hz
```
**Problem:** Sensor picks up electrical noise, makes data "jumpy"

**Solution:** Apply smoothing (moving average, exponential smoothing)

---

#### **Problem 5: No Context (No Time Windows)**
```
Single Reading:
  Temperature: 85Â°C

Question: Is this bad?
Answer: We don't know! Could be:
  - Normal operating temperature
  - Heating up (was 60Â°C 5 minutes ago) â† Concerning!
  - Cooling down (was 100Â°C 5 minutes ago) â† Good!
```

**Solution:** Create time windows showing history
```python
Window (last 30 cycles):
  current_temp: 85Â°C
  avg_temp: 75Â°C
  max_temp: 85Â°C
  temp_trend: +0.5Â°C/cycle  â† This tells us it's heating up!
  temp_std: 4.2Â°C
```

---

## ğŸ—ï¸ Preprocessing Service Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PREPROCESSING SERVICE                           â”‚
â”‚                                                                   â”‚
â”‚  INPUT                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Kafka Consumer                                           â”‚   â”‚
â”‚  â”‚ Topic: "sensor.raw"                                      â”‚   â”‚
â”‚  â”‚ Format: {"asset_id": "...", "sensor_id": "...",         â”‚   â”‚
â”‚  â”‚          "value": 45.2, "timestamp": "..."}             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                             â”‚
â”‚                     â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STEP 1: Validation                                       â”‚   â”‚
â”‚  â”‚ - Check required fields exist                            â”‚   â”‚
â”‚  â”‚ - Validate data types (number, not string)              â”‚   â”‚
â”‚  â”‚ - Check timestamp is recent (< 1 hour old)             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚ âœ… Valid data                              â”‚
â”‚                     â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STEP 2: Outlier Detection                                â”‚   â”‚
â”‚  â”‚ - Calculate z-score: (value - mean) / std                â”‚   â”‚
â”‚  â”‚ - If |z-score| > 3 â†’ outlier                            â”‚   â”‚
â”‚  â”‚ - Replace outliers with median                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                             â”‚
â”‚                     â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STEP 3: Missing Value Handling                           â”‚   â”‚
â”‚  â”‚ - Forward fill (use last known value)                    â”‚   â”‚
â”‚  â”‚ - If no previous value â†’ use sensor type default         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                             â”‚
â”‚                     â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STEP 4: Smoothing                                        â”‚   â”‚
â”‚  â”‚ - Apply exponential moving average                       â”‚   â”‚
â”‚  â”‚ - Smoothing factor Î± = 0.3                               â”‚   â”‚
â”‚  â”‚ - smoothed = Î± Ã— new_value + (1-Î±) Ã— old_value          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                             â”‚
â”‚                     â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STEP 5: Normalization                                    â”‚   â”‚
â”‚  â”‚ - Min-Max scaling: (x - min) / (max - min)              â”‚   â”‚
â”‚  â”‚ - Result: all values between 0 and 1                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                             â”‚
â”‚                     â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STEP 6: Time Window Creation                             â”‚   â”‚
â”‚  â”‚ - Group last 30 cycles per asset                         â”‚   â”‚
â”‚  â”‚ - Calculate window statistics:                           â”‚   â”‚
â”‚  â”‚   * mean, median, std, min, max                          â”‚   â”‚
â”‚  â”‚   * trend (linear regression slope)                      â”‚   â”‚
â”‚  â”‚   * rate of change                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                             â”‚
â”‚                     â–¼                                             â”‚
â”‚  OUTPUT                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Kafka Producer                                           â”‚   â”‚
â”‚  â”‚ Topic: "sensor.preprocessed"                             â”‚   â”‚
â”‚  â”‚ Format: {                                                â”‚   â”‚
â”‚  â”‚   "asset_id": "...",                                     â”‚   â”‚
â”‚  â”‚   "window": {                                            â”‚   â”‚
â”‚  â”‚     "cycles": 30,                                        â”‚   â”‚
â”‚  â”‚     "sensors": {                                         â”‚   â”‚
â”‚  â”‚       "temperature": {                                   â”‚   â”‚
â”‚  â”‚         "mean": 75.2, "std": 2.1,                        â”‚   â”‚
â”‚  â”‚         "trend": +0.5, "current": 76.0                   â”‚   â”‚
â”‚  â”‚       }                                                   â”‚   â”‚
â”‚  â”‚     }                                                     â”‚   â”‚
â”‚  â”‚   }                                                       â”‚   â”‚
â”‚  â”‚ }                                                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                   â”‚
â”‚  SIDE EFFECTS                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ TimescaleDB Storage                                      â”‚   â”‚
â”‚  â”‚ - Save preprocessed data for historical analysis         â”‚   â”‚
â”‚  â”‚ - Optimized time-series queries                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Prometheus Metrics                                       â”‚   â”‚
â”‚  â”‚ - Messages processed per second                          â”‚   â”‚
â”‚  â”‚ - Processing latency                                      â”‚   â”‚
â”‚  â”‚ - Outliers detected count                                â”‚   â”‚
â”‚  â”‚ - Errors count                                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’» Technology Stack Explained

### **FastAPI** (Web Framework)
**Why FastAPI and not Flask/Django?**

| Feature | FastAPI | Flask | Django |
|---------|---------|-------|--------|
| **Speed** | Very fast (async) | Slower (sync) | Slower (sync) |
| **Type hints** | Required âœ… | Optional | Optional |
| **Auto docs** | Yes âœ… (Swagger) | No | No |
| **Data validation** | Built-in âœ… (Pydantic) | Manual | Django Forms |
| **Async support** | Native âœ… | Limited | Limited |

**Example:**
```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

# Pydantic automatically validates input
class SensorData(BaseModel):
    sensor_id: str
    value: float  # Must be a number!
    timestamp: str

@app.post("/process")
async def process_sensor(data: SensorData):
    # If 'value' is not a float, FastAPI returns 422 error automatically!
    return {"processed": data.value * 2}
```

---

### **Kafka** (Message Streaming)
**Why Kafka and not REST APIs?**

**REST Approach (Bad for this use case):**
```
Ingestion â†’ HTTP POST â†’ Preprocessing â†’ HTTP POST â†’ Feature Extraction
```
Problems:
- âŒ If Preprocessing is down, Ingestion fails (tight coupling)
- âŒ No message persistence (data lost if service crashes)
- âŒ Synchronous (slow)
- âŒ Hard to scale

**Kafka Approach (Good!):**
```
Ingestion â†’ Kafka Topic â†’ Preprocessing â†’ Kafka Topic â†’ Feature Extraction
```
Benefits:
- âœ… Services decoupled (if Preprocessing is down, data waits in Kafka)
- âœ… Messages persisted (can replay if needed)
- âœ… Asynchronous (fast)
- âœ… Easy to scale (add more consumers)

---

### **Pandas** (Data Manipulation)
**Why Pandas?**

Handles time-series data elegantly:
```python
import pandas as pd

# Raw data
data = [
    {"time": "10:00", "temp": 75.2},
    {"time": "10:01", "temp": None},   # Missing!
    {"time": "10:02", "temp": 999.9},  # Outlier!
]

df = pd.DataFrame(data)

# One line to fix!
df['temp'] = df['temp'].fillna(method='ffill')  # Fill missing
df['temp'] = df['temp'].clip(0, 200)            # Cap outliers

# Calculate statistics
df['temp'].mean()      # 75.2
df['temp'].rolling(3).mean()  # 3-point moving average
```

---

## ğŸ”§ Key Preprocessing Techniques

### 1. Outlier Detection with Z-Score

**Concept:** How many standard deviations away from the mean?

```python
import numpy as np

def detect_outliers_zscore(values, threshold=3):
    """
    Z-score = (value - mean) / std

    If |z-score| > 3, the value is an outlier
    (99.7% of data is within 3 standard deviations)
    """
    mean = np.mean(values)
    std = np.std(values)

    z_scores = [(x - mean) / std for x in values]
    outliers = [abs(z) > threshold for z in z_scores]

    return outliers

# Example
temps = [75, 76, 75, 999, 74]  # 999 is clearly wrong
outliers = detect_outliers_zscore(temps)
# Result: [False, False, False, True, False]
```

**Why Z-score?**
- Simple and fast
- Works well for normally distributed data
- Threshold of 3 is standard (99.7% confidence)

---

### 2. Time Window Aggregation

**Concept:** Group sequential data points to see trends

```python
def create_time_window(df, window_size=30):
    """
    Create rolling windows of sensor data

    Example: Last 30 cycles of temperature readings
    """
    windows = []

    for i in range(len(df) - window_size + 1):
        window_data = df.iloc[i:i+window_size]

        window_features = {
            'mean': window_data['value'].mean(),
            'std': window_data['value'].std(),
            'min': window_data['value'].min(),
            'max': window_data['value'].max(),
            'trend': calculate_trend(window_data['value']),
            'current': window_data['value'].iloc[-1]
        }

        windows.append(window_features)

    return windows

def calculate_trend(values):
    """Linear regression slope"""
    x = np.arange(len(values))
    y = values.values
    slope = np.polyfit(x, y, 1)[0]  # Fit linear line, get slope
    return slope
```

**Example Output:**
```python
Window 1 (cycles 1-30):
  mean: 75.2Â°C
  std: 1.5Â°C
  trend: +0.1Â°C/cycle  # Slowly heating up
  current: 76Â°C

Window 2 (cycles 2-31):
  mean: 75.5Â°C
  std: 1.6Â°C
  trend: +0.2Â°C/cycle  # Heating up faster!
  current: 77Â°C
```

---

### 3. Exponential Smoothing

**Concept:** Smooth noisy data while giving more weight to recent values

```python
def exponential_smoothing(values, alpha=0.3):
    """
    Exponentially Weighted Moving Average (EWMA)

    alpha: Smoothing factor (0-1)
      - High alpha (0.7-0.9): Responsive to changes
      - Low alpha (0.1-0.3): Smoother but slower to react
    """
    smoothed = [values[0]]  # Start with first value

    for i in range(1, len(values)):
        new_value = alpha * values[i] + (1 - alpha) * smoothed[i-1]
        smoothed.append(new_value)

    return smoothed

# Example
raw = [45, 48, 44, 46, 47, 44, 49]
smoothed = exponential_smoothing(raw, alpha=0.3)
# Result: [45.0, 45.9, 45.33, 45.53, 45.97, 45.38, 46.47]
# Notice how smoothed values change gradually!
```

---

## ğŸ“ Service Directory Structure

```
services/preprocessing/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                  # FastAPI app entry point
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ settings.py          # Configuration (Kafka URLs, etc.)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ sensor_data.py       # Pydantic models for validation
â”‚   â”‚   â””â”€â”€ preprocessed_data.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ kafka_service.py     # Kafka consumer/producer
â”‚   â”‚   â”œâ”€â”€ preprocessing.py     # Core preprocessing logic
â”‚   â”‚   â””â”€â”€ storage_service.py   # TimescaleDB operations
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ outlier_detection.py
â”‚   â”‚   â”œâ”€â”€ normalization.py
â”‚   â”‚   â””â”€â”€ windowing.py
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ routes.py            # REST API endpoints
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â”œâ”€â”€ test_kafka.py
â”‚   â””â”€â”€ test_windowing.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ docker-compose.test.yml
```

---

## ğŸ“ Key Concepts Summary

### 1. **Why Preprocess?**
- Clean messy sensor data
- Remove outliers and fill missing values
- Normalize different scales
- Create time context (windows)
- Prepare data for ML models

### 2. **Key Techniques**
- **Outlier Detection:** Z-score, IQR
- **Missing Values:** Forward fill, interpolation
- **Smoothing:** Exponential weighted average
- **Normalization:** Min-max scaling
- **Windowing:** Rolling time windows with statistics

### 3. **Why These Technologies?**
- **FastAPI:** Fast, async, auto-validates
- **Kafka:** Decouples services, persists messages
- **Pandas:** Best tool for time-series data manipulation
- **TimescaleDB:** Optimized for time-series storage

---

## ğŸš€ Next: Let's Build It!

Now that you understand:
- âœ… What preprocessing does
- âœ… Why each technique is needed
- âœ… How the service fits in the architecture
- âœ… Which technologies we'll use

**Ready to write code?**

I'll guide you through:
1. Setting up the project structure
2. Writing the preprocessing logic
3. Connecting to Kafka
4. Creating the FastAPI service
5. Adding tests
6. Dockerizing the service

**Want to start building now, or do you have questions first?** ğŸ¯
